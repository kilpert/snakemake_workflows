#!/usr/bin/env python3

__description__ = """
MPI-IE workflow for DNA mapping

usage example:
    DNA-mapping -i input-dir -o output-dir mm10
"""


import argparse
import os
import sys
import textwrap
import snakePipes.common_functions as cf
import snakePipes.parserCommon as parserCommon


def parse_args(defaults={"verbose": False, "configFile": None,
                         "clusterConfigFile": None, "maxJobs": 5,
                         "snakemakeOptions": "--use-conda", "tempDir": None,
                         "mode": "mapping", "downsample": False, "trim": False,
                         "trimmer": "cutadapt", "trimmerOptions": "", "fastqc": False,
                         "qualimap": False, "dedup": False, "ext": ".fastq.gz",
                         "properPairs": False, "insertSizeMax": 1000,
                         "GCBias": False, "reads": ["_R1", "_R2"],
                         "bwBinSize": 25, "mapq": 0, "plotFormat": "png",
                         "alignerOpts": "", "mateOrientation": "--fr",
                         "UMIDedup": False, "UMIDedupOpts": "",
                         "UMIDedupSep": "_", "UMIBarcode": False,
                         "bcPattern": "NNNNCCCCCCCC"}):
    """
    Parse arguments from the command line.
    """
    mainArgs = parserCommon.mainArguments(defaults)
    snpArgs = parserCommon.snpArguments(defaults)

    parser = argparse.ArgumentParser(
        prog=sys.argv[0],
        formatter_class=argparse.RawDescriptionHelpFormatter,
        description=textwrap.dedent(__description__),
        parents=[mainArgs, snpArgs],
        add_help=False
    )


    # Workflow options
    optional = parser.add_argument_group('Options')
    optional.add_argument("-m", "--mode",
                          dest="mode",
                          help="workflow running modes (available: 'mapping,"
                          "allelic-mapping')(default: '%(default)s')",
                          default=defaults["mode"])

    parserCommon.commonOptions(optional, defaults)

    optional.add_argument("--alignerOpts",
                          help="Options that will be passed to bowtie2. You can specify things such as `--local` or "
                          "`--very-sensitive` here. The mate orientation and maximum insert size are specified "
                          "elsewhere. Read group information is set automatically. Note that you may need to escape "
                          "the first - (e.g., '\--very-fast'). Default: '%(default)s'.",
                          default=defaults["alignerOpts"])

    optional.add_argument("--mateOrientation",
                          help="The --fr, --ff, or --rf option for bowtie2 (default: '%(default)s')",
                          default=defaults["mateOrientation"])

    optional.add_argument("--qualimap",
                          dest="qualimap",
                          action="store_true",
                          help="activate Qualimap (default: '%(default)s')",
                          default=defaults["qualimap"])

    optional.add_argument("--dedup",
                          dest="dedup",
                          action="store_true",
                          help="retain only de-duplicated reads/read pairs "
                          "(given single-/paired-end data), recommended for "
                          "ChIP-seq data (default: '%(default)s')",
                          default=defaults["dedup"])

    optional.add_argument("--properPairs",
                          action="store_true",
                          help="retain only reads mapping in proper pairs (default: '%(default)s')",
                          default=defaults["properPairs"])

    optional.add_argument("--mapq",
                          dest="mapq",
                          metavar="INT",
                          help="retain only reads with at least the given "
                          "mapping quality. We recommend using"
                          "mapq of 3 or more for ChIP-seq to remove all true "
                          "multimapping reads. (default: '%(default)s')",
                          type=int,
                          default=defaults["mapq"])

    optional.add_argument("--insertSizeMax",
                          help="Maximum insert size allowed during mapping (default: '%(default)s')",
                          type=int,
                          default=defaults["insertSizeMax"])

    optional.add_argument("--GCBias",
                          action="store_true",
                          help="run computeGCBias quality control "
                          "(long runtime!). Note that GCBias analysis is "
                          "skipped if downsampling is specified "
                          "(default: '%(default)s')",
                          default=defaults["GCBias"])

    return parser


def main():
    baseDir, workflowDir, defaults = cf.setDefaults(os.path.basename(__file__))

    # get command line arguments
    parser = parse_args(defaults)
    args = parser.parse_args()
    args, defaults = cf.handleUserArgs(args, defaults, parse_args)

    # we also add these paths to config, although we don't use them in the Snakefile
    args.baseDir = baseDir

    # Common arguments
    cf.checkCommonArguments(args, baseDir, outDir=True)

    ## Begin workflow-specific code
    # check for Allele-specific mapping mode
    args.allele_mode = cf.checkAlleleParams(args)
    # convert file path to abspath
    if args.allele_mode == "create_and_map":
        args.VCFfile = os.path.abspath(args.VCFfile)
    elif args.allele_mode == "map_only":
        args.SNPfile = os.path.abspath(args.SNPfile)
        args.NMaskedIndex = os.path.abspath(args.NMaskedIndex)

    # clean up filtered_bam if needed appropriate
    os.makedirs(args.outdir, exist_ok=True)
    filt = ""
    if args.dedup:
        filt += "-F 1024 "
        assert args.UMIDedup is False, "\nPlease use either --UMIDedup (UMI-tools dedup) or --dedup (via sambamba and samtools)!\n"
        "should be called!"
    if args.properPairs:
        filt += "-f 2 "
    if args.mapq is not None and args.mapq > 0:
        filt += "-q {} ".format(args.mapq)
    filter_rules = os.path.join(args.outdir, "filter_rules")
    if os.path.exists(filter_rules):
        f = open(filter_rules)
        cont = f.read()
        f.close()
        if cont != filt:
            f = open(filter_rules, "w")
            f.write(filt)
            f.close()
    else:
        f = open(filter_rules, "w")
        f.write(filt)
        f.close()
    ## End workflow-specific clode

    # Handle YAML and log files

    snakemake_cmd = cf.commonYAMLandLogs(baseDir, workflowDir, defaults, args, __file__)
    logfile_name = cf.logAndExport(args, os.path.basename(__file__))

    # Run everything
    cf.runAndCleanup(args, snakemake_cmd, logfile_name)

    #CreateDAG
    cf.print_DAG(args,snakemake_cmd, __file__,defaults)


if __name__ == "__main__":
    main()
