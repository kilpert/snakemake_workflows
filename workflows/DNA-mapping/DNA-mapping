#!/usr/bin/env python3

__version__ = "0.6"

__description__ = """
DNA-mapping workflow v{version} - MPI-IE workflow for DNA mapping

usage example:
    DNA-mapping -i input-dir -o output-dir mm10
""".format(version=__version__)


import argparse
import os
import signal
import subprocess
import sys
import textwrap
import time
import shutil
import yaml
import inspect
from glob import glob

sys.path.append(os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.realpath(inspect.getfile(inspect.currentframe()) )))))+"/shared/")


import common_functions as cf


def parse_args(defaults={"verbose":None,"configfile":None,"cluster_configfile":None,"max_jobs":None,"snakemake_options":None,"tempdir":None,
                         "mode":None, "downsample":None, "trim":None,"trim_prg":None,"trim_options":None, "fastqc":None,
                         "qualimap":None, "dedup":None, "properpairs":None, "insert_size_max":None, "gcbias":None,
                         "bw_binsize":None, "mapq":None, "plot_format":None}):
    """
    Parse arguments from the command line.
    """

    parser = argparse.ArgumentParser(
        prog=sys.argv[0],
        formatter_class=argparse.RawDescriptionHelpFormatter,
        description=textwrap.dedent(__description__),
        add_help=False
    )

    #optional = parser._action_groups.pop() # Edited this line

    ## positional/required
    parser.add_argument("genome",
                        metavar="GENOME",
                        help="Genome acronym of target organism (supported: 'dm3', 'dm6', 'hs37d5', 'hg38', 'mm9', 'mm10', 'SchizoSPombe_ASM294v2')")

    required = parser.add_argument_group('required arguments')
    required.add_argument("-i", "--input-dir",
                        dest="indir",
                        help="input directory containing the FASTQ files, either paired-end OR single-end data",
                        required=True)

    required.add_argument("-o", "--output-dir",
                        dest="outdir",
                        help="output directory",
                        required=True)

    general = parser.add_argument_group('general arguments')

    general.add_argument("-h", "--help",
                        action="help",
                        help="show this help message and exit")

    general.add_argument("-v", "--verbose",
                        dest="verbose",
                        action="store_true",
                        help="verbose output (default: '%(default)s')",
                        default=defaults["verbose"])

    general.add_argument("-c", "--configfile",
                        dest="configfile",
                        help="configuration file: config.yaml. In absence of a config file, the default options from the "
                        "workflows would be selected from /workflows/<workflow_name>/defaults.yaml (default: '%(default)s')",
                        default=defaults["configfile"])

    general.add_argument("--cluster_configfile",
                        dest="cluster_configfile",
                        help="configuration file for cluster usage. In absence, the default options "
                        "from shared/cluster.yaml and workflows/[workflow]/cluster.yaml would be selected (default: '%(default)s')",
                        default=defaults["cluster_configfile"])

    general.add_argument("-j", "--jobs",
                        dest="max_jobs",
                        metavar="INT",
                        help="maximum number of concurrently submitted Slurm jobs / cores if workflow is run locally (default: '%(default)s')",
                        type=int,
                        default=defaults["max_jobs"])

    general.add_argument("--local",
                        dest="local",
                        action="store_true",
                        default=False,
                        help="run workflow locally; default: jobs are submitted to Slurm queue (default: '%(default)s')")

    general.add_argument("--snakemake_options",
                        dest="snakemake_options",
                        metavar="STR",
                        type=str,
                        help="Snakemake options to be passed directly to snakemake, e.g. use "
                        "--snakemake_options='--dryrun --rerun-incomplete --unlock --forceall'. (default: '%(default)s')",
                        default=defaults["snakemake_options"])

    general.add_argument("--tempdir",
                        dest="tempdir",
                        type=str,
                        help="used prefix path for temporary directory created via mktemp. Created temp dir gets exported as "
                        "$TMPDIR and is removed at the end of this wrapper! (default: '%(default)s')",
                        default=defaults["tempdir"])

    general.add_argument("--DAG",
                         dest="createDAG",
                         action="store_true",
                         help="If specified, a file called pipeline.pdf is produced in the output directory that shows the rules used and their relationship to each other.")

    ## optional
    optional = parser.add_argument_group('Optional arguments')
    optional.add_argument("-m", "--mode",
                         dest="mode",
                         help="workflow running modes (available: 'mapping, allelic-mapping')"
                         " (default: '%(default)s')",
                         default=defaults["mode"])

    parser.add_argument("--downsample",
                        dest="downsample",
                        metavar="INT",
                        help="downsample the given number of reads randomly from of each FASTQ file (default: '%(default)s')",
                        type=int,
                        default=defaults["downsample"])

    parser.add_argument("--trim",
                        dest="trim",
                        action="store_true",
                        help="Activate fastq read trimming. If activated, Illumina adaptors are trimmed by default. "
                        "Additional parameters can be specified under --trim_options (default: '%(default)s')",
                        default=defaults["trim"])

    parser.add_argument("--trim_prg",
                        dest="trim_prg",
                        choices=['cutadapt', 'trimgalore'],
                        help="trimming program: Cutadapt or TrimGalore (default: '%(default)s')",
                        default=defaults["trim_prg"])

    parser.add_argument("--trim_options",
                        dest="trim_options",
                        metavar="STR",
                        type=str,
                        help="Additional option string for trimming program of choice. (default: '%(default)s')",
                        default=defaults["trim_options"])

    parser.add_argument("--qualimap",
                        dest="qualimap",
                        action="store_true",
                        help="activate Qualimap (default: '%(default)s')",
                        default=defaults["qualimap"])

    parser.add_argument("--fastqc",
                        dest="fastqc",
                        action="store_true",
                        help="run FastQC read quality control (default: '%(default)s')",
                        default=defaults["fastqc"])

    parser.add_argument("--dedup",
                        dest="dedup",
                        action="store_true",
                        help="retain only de-duplicated reads/read pairs (given single-/paired-end data), "
                        "recommended for ChIP-seq data (default: '%(default)s')",
                        default=defaults["dedup"])

    parser.add_argument("--properpairs",
                        dest="properpairs",
                        action="store_true",
                        help="retain only reads mapping in proper pairs (default: '%(default)s')",
                        default=defaults["properpairs"])

    parser.add_argument("--mapq",
                        dest="mapq",
                        metavar="INT",
                        help="retain only reads with at least the given mapping quality. We recommend using"
                        "mapq of 3 or more for ChIP-seq to remove all true multimapping reads. (default: '%(default)s')",
                        type=int,
                        default=defaults["mapq"])

    parser.add_argument("--bw-binsize",
                        dest="bw_binsize",
                        metavar="INT",
                        help="bin size of output files in bigWig format (default: '%(default)s')",
                        type=int,
                        default=defaults["bw_binsize"])

    parser.add_argument("--insert-size",
                        dest="insert_size_max",
                        metavar="INT",
                        help="Maximum insert size allowed during mapping (default: '%(default)s')",
                        type=int,
                        default=defaults["insert_size_max"])

    parser.add_argument("--gcbias",
                        dest="gcbias",
                        action="store_true",
                        help="run computeGCBias quality control (long runtime!). Note that "
                        "gcbias analysis is skipped if downsampling is specified (default: '%(default)s')",
                        default=defaults["gcbias"])

    parser.add_argument("--plotFormat",
                        dest="plot_format",
                        choices=['png', 'pdf', 'None'],
                        metavar="STR",
                        type=str,
                        help="Format of the output plots from deeptools. Select 'none' for no plot (default: '%(default)s')",
                        default=defaults["plot_format"])

    snpargs = parser.add_argument_group('allele-specific mapping arguments')
    snpargs.add_argument("--VCFfile",
                        metavar="STR",
                        help="VCF file to create N-masked genomes (default: 'None')",
                        default='',
                        type=str)
    snpargs.add_argument("--strains",
                        dest="strains",
                        metavar="STR",
                        help="Name or ID of SNP strains separated by comma (default: 'None')",
                        default='',
                        type=str)
    snpargs.add_argument("--SNPfile",
                        metavar="STR",
                        help="File containing SNP locations (default: 'None')",
                        default='',
                        type=str)
    snpargs.add_argument("--Nmasked_index",
                        metavar="STR",
                        help="N-masked index of the reference genome (default: 'None')",
                        default='',
                        type=str)

    return parser


def main():

   ## basic paths only used in wrapper
    this_script_dir = os.path.dirname(os.path.realpath(__file__))
    main_dir_path = cf.get_snakepipes_path()

    ## defaults
    defaults = cf.load_configfile(os.path.join(this_script_dir, "defaults.yaml"),False)

    ## get command line arguments
    parser = parse_args(defaults)
    args = parser.parse_args()

    ## we also add these paths to config, although we don't use them in the Snakefile
    args.this_script_dir = this_script_dir
    args.main_dir_path = main_dir_path

    args.outdir = os.path.abspath(args.outdir)
    args.cluster_logs_dir = os.path.join(args.outdir, "cluster_logs")
    # check for Allele-specific mapping mode
    args.allele_mode = cf.checkAlleleParams(args)
    # convert file path to abspath
    if args.allele_mode == "create_and_map":
        args.VCFfile = os.path.abspath(args.VCFfile)
    elif args.allele_mode == "map_only":
        args.SNPfile = os.path.abspath(args.SNPfile)
        args.Nmasked_index = os.path.abspath(args.Nmasked_index)

## checks for parameters necessary in wrapper
# 1. Dir path
    if os.path.exists(args.indir):
        args.indir = os.path.abspath(args.indir)
    else:
        print("\nError! Input dir not found! ({})\n".format(args.indir))
        exit(1)
# 2. config file
    if args.configfile and not os.path.exists(args.configfile):
        print("\nError! Provided configfile (-c) not found! ({})\n".format(args.configfile))
        exit(1)
# 3. get abspath from user provided genome/organism file
    if not os.path.isfile(os.path.join(main_dir_path, "shared", "organisms", args.genome + ".yaml")) and os.path.isfile(args.genome):
        args.genome = os.path.abspath(args.genome)

    ## merge configuration dicts
    config = defaults   # 1) form defaults.yaml
    if args.configfile:
        user_config = cf.load_configfile(args.configfile,False)
        config = cf.merge_dicts(config, user_config) # 2) form user_config.yaml
    config_wrap = cf.config_diff(vars(args),defaults) # 3) from wrapper parameters
    config = cf.merge_dicts(config, config_wrap)

    ## Output directory + log directory
    subprocess.call("[ -d {cluster_logs_dir} ] || mkdir -p {cluster_logs_dir}".format(cluster_logs_dir=args.cluster_logs_dir), shell=True)

    ## save to configs.yaml in outdir
    cf.write_configfile(os.path.join(args.outdir,'config.yaml'),config)

    ## merge cluster config files: 1) global one, 2) workflow specific one, 3) user provided one
    cluster_config = cf.load_configfile(cf.get_snakepipes_path()+"/shared/cluster.yaml",False)
    cluster_config = cf.merge_dicts(cluster_config, cf.load_configfile(os.path.join(this_script_dir,"cluster.yaml"),False), )

    if args.cluster_configfile:
        user_cluster_config = cf.load_configfile(args.cluster_configfile,False)
        cluster_config = cf.merge_dicts(cluster_config, user_cluster_config) # 2) merge/override variables from user_config.yaml
    cf.write_configfile(os.path.join(args.outdir,'cluster_config.yaml'),cluster_config)

    snakemake_cmd = """
                    snakemake {snakemake_options} --latency-wait {latency_wait} --snakefile {snakefile} --jobs {max_jobs} --directory {outdir} --configfile {configfile}
                    """.format( latency_wait = cluster_config["snakemake_latency_wait"],
                                snakefile = os.path.join(args.this_script_dir, "Snakefile"),
                                max_jobs = args.max_jobs,
                                outdir = args.outdir,
                                snakemake_options = str(args.snakemake_options or ''),
                                configfile = os.path.join(args.outdir,'config.yaml'),
                              ).split()

    # clean up filtered_bam if needed appropriate
    filt = ""
    if args.dedup:
        filt += "-F 1024 "
    if args.properpairs:
        filt += "-f 2 "
    if args.mapq is not None and args.mapq > 0:
        filt += "-q {} ".format(args.mapq)
    filter_rules = os.path.join(args.outdir, "filter_rules")
    if os.path.exists(filter_rules):
        f = open(filter_rules)
        cont = f.read()
        f.close()
        if cont != filt:
            f = open(filter_rules, "w")
            f.write(filt)
            f.close()
    else:
        f = open(filter_rules, "w")
        f.write(filt)
        f.close()

    # Produce the DAG if desired
    if args.createDAG:
        oldVerbose = config['verbose']
        config['verbose'] = False
        cf.write_configfile(os.path.join(args.outdir,'config.yaml'),config)
        DAGproc = subprocess.Popen(snakemake_cmd + ['--rulegraph'], stdout=subprocess.PIPE)
        _ = open("{}/pipeline.pdf".format(args.outdir), "wb")
        foo = subprocess.check_call(["dot", "-Tpdf"], stdin=DAGproc.stdout, stdout=_)
        _.close()
        config['verbose'] = oldVerbose
        cf.write_configfile(os.path.join(args.outdir,'config.yaml'),config)

    if args.verbose:
        snakemake_cmd.append("--printshellcmds")

    if not args.local:
        snakemake_cmd += ["--cluster-config",
                         os.path.join(args.outdir,'cluster_config.yaml'),
                         "--cluster", "'"+cluster_config["snakemake_cluster_cmd"],
                         args.cluster_logs_dir, "--name {rule}.snakemake'"]

    ## Write snakemake_cmd to log file
    fnames = glob(os.path.join(args.outdir, 'DNA-mapping_run-[0-9*].log'))
    if len(fnames) == 0:
        n = 1 # no matching files, this is the first run
    else:
        fnames.sort(key=os.path.getctime)
        n = int(fnames[-1].split("-")[-1].split(".")[0]) + 1 # get new run number
    # append the new run number to the file name
    logfile_name = "DNA-mapping_run-{}.log".format(n) 

    snakemake_log = "2>&1 | tee -a {}/{}".format(args.outdir, logfile_name).split()

    ## create local temp dir and add this path to environment as $TMPDIR variable
    ## on SLURM: $TMPDIR is set, created and removed by SlurmEasy on cluster node
    temp_path = cf.make_temp_dir(args.tempdir, args.outdir, args.verbose)
    snakemake_exports = ("export TMPDIR="+temp_path+" && ").split()

    cmd = " ".join(snakemake_exports + snakemake_cmd + snakemake_log)

    if args.verbose:
        print("\n", cmd, "\n")

    # write log file
    with open(os.path.join(args.outdir, logfile_name), "w") as f:
        f.write(" ".join(sys.argv)+"\n\n")
        f.write(cmd+"\n\n")

    ## Run snakemake
    p = subprocess.Popen(cmd, shell=True)
    if args.verbose:
        print("PID:", p.pid, "\n")
    try:
        p.wait()
    except:
        print("\nWARNING: Snakemake terminated!!!")
        if p.returncode != 0:
            if p.returncode:
                print("Returncode:", p.returncode)

            # kill snakemake and child processes
            subprocess.call(["pkill", "-SIGTERM", "-P", str(p.pid)])
            print("SIGTERM sent to PID:", p.pid)

    ## remove temp dir
    if (temp_path != "" and os.path.exists(temp_path)):
        shutil.rmtree(temp_path, ignore_errors=True)
        if args.verbose:
            print("temp dir removed: "+temp_path+"\n")


if __name__ == "__main__":
    main()
